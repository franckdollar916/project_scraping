# ğŸ“Œ Projet de Scraping et Visualisation des DonnÃ©es

## ğŸš€ Introduction
Ce projet consiste Ã  scraper des donnÃ©es depuis un site web, les stocker dans une base de donnÃ©es PostgreSQL, les exposer via une API FastAPI et les afficher dans une interface web avec Dash. Lâ€™ensemble du projet est conteneurisÃ© avec Docker et orchestrÃ© via `docker-compose`.

---

## ğŸ› ï¸ Technologies UtilisÃ©es
âœ… **Scraping** : `BeautifulSoup`, `Requests`  
âœ… **Base de donnÃ©es** : `PostgreSQL`  
âœ… **API** : `FastAPI`  
âœ… **Interface Web** : `Dash (Plotly)`  
âœ… **Conteneurisation** : `Docker` & `Docker-Compose`

---

## ğŸ“ Structure du Projet
```
projet_scraping_IMDB/
â”‚â”€â”€ Scraper/          # Scraping des donnÃ©es
â”‚â”€â”€ Database/         # Base de donnÃ©es PostgreSQL
â”‚â”€â”€ API/              # API FastAPI pour l'accÃ¨s aux donnÃ©es
â”‚â”€â”€ WebApp/           # Interface Web avec Dash
â”‚â”€â”€ docker-compose.yml # Orchestration Docker
â”‚â”€â”€ README.md         # Ce fichier ğŸ“„
```

---

## âš™ï¸ Installation & Lancement
### ğŸ”¹ **1. PrÃ©requis**
- Docker & Docker-Compose installÃ©s

### ğŸ”¹ **2. Cloner le projet**
```bash
git clone https://github.com/franckdollar916/projet_scraping.git
cd projet_scraping_IMDB
```

### ğŸ”¹ **3. Construire et dÃ©marrer les services**
```bash
docker-compose up --build
```
ğŸ“Œ **Attendre quelques secondes** le temps que la base de donnÃ©es PostgreSQL dÃ©marre.

### ğŸ”¹ **4. Tester les services**
ğŸ“¡ **API** (Swagger Docs) : [http://localhost:8000/docs](http://localhost:8000/docs)  
ğŸ“Š **Interface Web** : [http://localhost:8050](http://localhost:8050)  

---

## ğŸ› ï¸ FonctionnalitÃ©s
âœ” **Scraping des donnÃ©es** depuis un site web.  
âœ” **Stockage des donnÃ©es** dans PostgreSQL.  
âœ” **AccÃ¨s via une API** FastAPI en JSON.  
âœ” **Affichage dynamique** des donnÃ©es dans une interface web.  
âœ” **DÃ©ploiement facilitÃ©** avec Docker.

---

## ğŸ”¥ ProblÃ¨mes rencontrÃ©s et solutions
### âŒ `ModuleNotFoundError: No module named 'Database'`
ğŸ“Œ **Solution** : Modification du `Dockerfile` du Scraper pour copier correctement les fichiers :
```dockerfile
COPY Scraper /app/
```

### âŒ `connection to server at "database" failed: Connection refused`
ğŸ“Œ **Solution** : Ajout dâ€™un **dÃ©lai dâ€™attente** dans `docker-compose.yml` avant dâ€™exÃ©cuter lâ€™API :
```yaml
entrypoint: ["/bin/sh", "-c", "sleep 10 && python /app/database.py"]
```

### âŒ `No such file or directory: '/app/Scraper/requirements.txt'`
ğŸ“Œ **Solution** : VÃ©rification du chemin dans le `Dockerfile` et correction avec :
```dockerfile
COPY . /app/
```

### âŒ `database "books_db" already exists`
ğŸ“Œ **Solution** : Suppression de la ligne `CREATE DATABASE books_db;` dans `schema.sql`.

---

## ğŸ¯ AmÃ©liorations futures
ğŸš€ **Scraping en temps rÃ©el avec Celery**  
ğŸš€ **Ajout dâ€™Elasticsearch pour une recherche avancÃ©e**  
ğŸš€ **Utilisation de Redis pour la mise en cache**  


